{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD--Classification-223.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPLpNeqFvTfUYuXCKXcOup0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gndede/python/blob/main/SGD_Classification_223.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SGD Classification Example with SGDClassifier in Python**\n",
        "\n",
        "Applying the Stochastic Gradient Descent (SGD) to the regularized linear methods can help building an estimator for classification and regression problems.\n",
        "\n",
        "    Scikit-learn API provides the SGDClassifier class to implement SGD method for classification problems. The SGDClassifier applies regularized linear model with SGD learning to build an estimator. The SGD classifier works well with large-scale datasets and it is an efficient and easy to implement method.\n",
        "\n",
        "    In this tutorial, we'll briefly learn how to classify data by using the SGDClassifier class in Python. The tutorial covers:\n",
        "\n",
        "1. Preparing the data\n",
        "2. Training the model\n",
        "3. Predicting and accuracy check\n",
        "4. Iris dataset classification example\n",
        "5. Source code listing\n",
        "\n",
        "We'll start by loading the required libraries and functions."
      ],
      "metadata": {
        "id": "IxSK27nsecrZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DwWujdeeZLE"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import scale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the data**\n",
        "\n",
        "    First, we'll generate random classification dataset with make_classification() function. The dataset contains 3 classes with 10 features and the number of samples is 5000.\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "t7WscR23e4Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = make_classification(n_samples=5000, n_features=10, \n",
        "                           n_classes=3, \n",
        "                           n_clusters_per_class=1)"
      ],
      "metadata": {
        "id": "mi6hdWgNe_EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll split the data into train and test parts. Here, we'll extract 15 percent of it as test data."
      ],
      "metadata": {
        "id": "zG9uPSMHfGpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.15)"
      ],
      "metadata": {
        "id": "PR8etpWafJrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model.\n",
        "Next, we'll define the classifier by using the SGDClassifier class. Then fit it on the train data. "
      ],
      "metadata": {
        "id": "ZSG2dA6DfNxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgdc = SGDClassifier(max_iter=1000, tol=0.01)\n",
        "print(sgdc)\n",
        " \n",
        "sgdc.fit(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "sKik1DPkfVcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the training the classifier, we'll check the model accuracy score.\n"
      ],
      "metadata": {
        "id": "5ZTUJ0aAfalv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = sgdc.score(xtrain, ytrain)\n",
        "print(\"Training score: \", score) \n",
        " \n",
        "#Training Score:  0.8454117647058823 0.9670588235294117"
      ],
      "metadata": {
        "id": "4GAyVf_BfdMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting and accuracy check**\n",
        "\n",
        "     Now, we can predict the test data by using the trained model. After the prediction, we'll check the accuracy level by using the confusion matrix function."
      ],
      "metadata": {
        "id": "s5xaYm4ifn5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = sgdc.predict(xtest)\n",
        "\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "print(cm) \n",
        " \n",
        "'''[[215   6  30]\n",
        " [  8 236   4]\n",
        " [ 54  21 176]]'''"
      ],
      "metadata": {
        "id": "z1WRbeqbfwD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also create a classification report by using classification_report() function on predicted data to check the other accuracy metrics."
      ],
      "metadata": {
        "id": "QtvyAaE2f3xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cr = classification_report(ytest, ypred)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "oK_n977cf22a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iris dataset classification example**\n",
        "\n",
        "We'll load the Iris dataset with load_iris() function, extract the x and y parts, then split into the train and test parts. It is better to scale data to improve the training accuracy.\n",
        "\n",
        "# Iris dataset example \n"
      ],
      "metadata": {
        "id": "ZWoYj7vLgJBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "x, y = iris.data, iris.target\n",
        "x = scale(x)\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)"
      ],
      "metadata": {
        "id": "YdxBNEkjgXgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll use the same method mentioned above."
      ],
      "metadata": {
        "id": "2Qv8mD_ogbrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgdc = SGDClassifier(max_iter=1000, tol=0.01)\n",
        "print(sgdc)\n",
        "\n",
        "sgdc.fit(xtrain, ytrain)\n",
        "score = sgdc.score(xtrain, ytrain)\n",
        "print(\"Score: \", score)\n",
        "\n",
        "ypred = sgdc.predict(xtest)\n",
        "\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(ytest, ypred)\n",
        "print(cr) \n"
      ],
      "metadata": {
        "id": "tuFvSb4ogi9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   In this tutorial, we've briefly learned how to classify data by using Scikit-learn's SGDClassifier class in Python. The full source code is listed below."
      ],
      "metadata": {
        "id": "56KbRCz0gyDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Full source code:\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "x, y = make_classification(n_samples=5000, n_features=10, \n",
        "                           n_classes=3, n_clusters_per_class=1)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)\n",
        "\n",
        "sgdc = SGDClassifier(max_iter=1000, tol=0.01)\n",
        "print(sgdc)\n",
        "\n",
        "sgdc.fit(xtrain, ytrain)\n",
        "\n",
        "score = sgdc.score(xtrain, ytrain)\n",
        "print(\"Training score: \", score)\n",
        "\n",
        "ypred = sgdc.predict(xtest)\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(ytest, ypred)\n",
        "print(cr)\n",
        "\n",
        "\n",
        "# Iris dataset example\n",
        "iris = load_iris()\n",
        "x, y = iris.data, iris.target\n",
        "x = scale(x)\n",
        "\n",
        "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)\n",
        "\n",
        "sgdc = SGDClassifier(max_iter=1000, tol=0.01)\n",
        "print(sgdc)\n",
        "\n",
        "sgdc.fit(xtrain, ytrain)\n",
        "score = sgdc.score(xtrain, ytrain)\n",
        "print(\"Score: \", score)\n",
        "\n",
        "ypred = sgdc.predict(xtest)\n",
        "\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(ytest, ypred)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "-IRLPSeHgrdW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
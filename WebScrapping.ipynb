{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "WebScrapping.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gndede/python/blob/main/WebScrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0W0gan0Ps8j"
      },
      "source": [
        "#extracting content of web pages. This is a web scrapping lab\n",
        "#In this lab exercise, we'll scrape Goodread's Best Books list:\n",
        "#link to scrap https://www.goodreads.com/list/show/1.Best_Books_Ever?page=1 .\n",
        "#We'll walk through scraping the list pages for the book names/urls\n",
        "\n",
        "#Table of Contents\n",
        "\n",
        "#1: Learning Goals \n",
        "#2: Exploring the Web pages and downloading them \n",
        "#3: Parse the page, extract book urls \n",
        "#4: Parse a book page, extract book properties \n",
        "#5: Set up a pipeline for fetching and parsing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q39KRLwxPs8n"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "pd.set_option('display.width', 500)\n",
        "pd.set_option('display.max_columns', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlk2pny-Ps8o"
      },
      "source": [
        "import time, requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQUANIxrPs8o",
        "outputId": "66a0f59a-8f22-49b7-b413-1d77b2c5ea18"
      },
      "source": [
        "#1. Exploring the web pages and downloading them\n",
        "\n",
        "URLSTART=\"https://www.goodreads.com\"\n",
        "BESTBOOKS=\"/list/show/1.Best_Books_Ever?page=\"\n",
        "url = URLSTART+BESTBOOKS+'1'\n",
        "print(url)\n",
        "page = requests.get(url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.goodreads.com/list/show/1.Best_Books_Ever?page=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GusYEQapPs8p",
        "outputId": "eb2f4cfa-30d3-4758-a60d-d67c692e9b88"
      },
      "source": [
        "#We can see properties of the page. Most relevant are status_code and text. \n",
        "#The first line tells us if the web-page was found, and if found , ok.\n",
        "# 200 is good/ok\n",
        "\n",
        "page.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "WYhA9XmwPs8q",
        "outputId": "50863df0-ce00-4d36-ed0c-a5d55e5817b7"
      },
      "source": [
        "page.text[:5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<!DOCTYPE html>\\n<html class=\"desktop withSiteHeaderTopFullImage\\n\">\\n<head>\\n  <title>Best Books Ever (56597 books)</title>\\n\\n<meta content=\\'55,104 books based on 218585 votes: The Hunger Games by Suzanne Collins, Harry Potter and the Order of the Phoenix by J.K. Rowling, To Kill a Mockingbird...\\' name=\\'description\\'>\\n<meta content=\\'telephone=no\\' name=\\'format-detection\\'>\\n<link href=\\'https://www.goodreads.com/list/show/1.Best_Books_Ever\\' rel=\\'canonical\\'>\\n\\n\\n\\n    <script type=\"text/javascript\"> var ue_t0=window.ue_t0||+new Date();\\n </script>\\n  <script type=\"text/javascript\">\\n    var ue_mid = \"A1PQBFHBHS6YH1\";\\n    var ue_sn = \"www.goodreads.com\";\\n    var ue_furl = \"fls-na.amazon.com\";\\n    var ue_sid = \"984-1350747-1953385\";\\n    var ue_id = \"Y329AZWY9MWJGHP7XKEM\";\\n\\n    (function(e){var c=e;var a=c.ue||{};a.main_scope=\"mainscopecsm\";a.q=[];a.t0=c.ue_t0||+new Date();a.d=g;function g(h){return +new Date()-(h?0:a.t0)}function d(h){return function(){a.q.push({n:h,a:arguments,t:a.d()})}}function b(m,l,h,j,i){var k={m:m,f:l,l:h,c:\"\"+j,err:i,fromOnError:1,args:arguments};c.ueLogError(k);return false}b.skipTrace=1;e.onerror=b;function f(){c.uex(\"ld\")}if(e.addEventListener){e.addEventListener(\"load\",f,false)}else{if(e.attachEvent){e.attachEvent(\"onload\",f)}}a.tag=d(\"tag\");a.log=d(\"log\");a.reset=d(\"rst\");c.ue_csm=c;c.ue=a;c.ueLogError=d(\"err\");c.ues=d(\"ues\");c.uet=d(\"uet\");c.uex=d(\"uex\");c.uet(\"ue\")})(window);(function(e,d){var a=e.ue||{};function c(g){if(!g){return}var f=d.head||d.getElementsByTagName(\"head\")[0]||d.documentElement,h=d.createElement(\"script\");h.async=\"async\";h.src=g;f.insertBefore(h,f.firstChild)}function b(){var k=e.ue_cdn||\"z-ecx.images-amazon.com\",g=e.ue_cdns||\"images-na.ssl-images-amazon.com\",j=\"/images/G/01/csminstrumentation/\",h=e.ue_file||\"ue-full-11e51f253e8ad9d145f4ed644b40f692._V1_.js\",f,i;if(h.indexOf(\"NSTRUMENTATION_FIL\")>=0){return}if(\"ue_https\" in e){f=e.ue_https}else{f=e.location&&e.location.protocol==\"https:\"?1:0}i=f?\"https://\":\"http://\";i+=f?g:k;i+=j;i+=h;c(i)}if(!e.ue_inline){if(a.loadUEFull){a.loadUEFull()}else{b()}}a.uels=c;e.ue=a})(window,document);\\n\\n    if (window.ue && window.ue.tag) { window.ue.tag(\\'list:show:signed_out\\', ue.main_scope);window.ue.tag(\\'list:show:signed_out:desktop\\', ue.main_scope); }\\n  </script>\\n\\n  <!-- * Copied from https://info.analytics.a2z.com/#/docs/data_collection/csa/onboard */ -->\\n<script>\\n  //<![CDATA[\\n    !function(){function n(n,t){var r=i(n);return t&&(r=r(\"instance\",t)),r}var r=[],c=0,i=function(t){return function(){var n=c++;return r.push([t,[].slice.call(arguments,0),n,{time:Date.now()}]),i(n)}};n._s=r,this.csa=n}();\\n    \\n    if (window.csa) {\\n      window.csa(\"Config\", {\\n        \"Application\": \"GoodreadsMonolith\",\\n        \"Events.SushiEndpoint\": \"https://unagi.amazon.com/1/events/com.amazon.csm.csa.prod\",\\n        \"Events.Namespace\": \"csa\",\\n        \"CacheDetection.RequestID\": \"Y329AZWY9MWJGHP7XKEM\",\\n        \"ObfuscatedMarketplaceId\": \"A1PQBFHBHS6YH1\"\\n      });\\n    \\n      window.csa(\"Events\")(\"setEntity\", {\\n        session: { id: \"984-1350747-1953385\" },\\n        page: {requestId: \"Y329AZWY9MWJGHP7XKEM\", meaningful: \"interactive\"}\\n      });\\n    }\\n    \\n    var e = document.createElement(\"script\"); e.src = \"https://m.media-amazon.com/images/I/41mrkPcyPwL.js\"; document.head.appendChild(e);\\n  //]]>\\n</script>\\n\\n\\n          <script type=\"text/javascript\">\\n        if (window.Mobvious === undefined) {\\n          window.Mobvious = {};\\n        }\\n        window.Mobvious.device_type = \\'desktop\\';\\n        </script>\\n\\n\\n  \\n<script src=\"https://s.gr-assets.com/assets/webfontloader-a550a17efafeccd666200db5de8ec913.js\"></script>\\n<script>\\n//<![CDATA[\\n\\n  WebFont.load({\\n    classes: false,\\n    custom: {\\n      families: [\"Lato:n4,n7,i4\", \"Merriweather:n4,n7,i4\"],\\n      urls: [\"https://s.gr-assets.com/assets/gr/fonts-e256f84093cc13b27f5b82343398031a.css\"]\\n    }\\n  });\\n\\n//]]>\\n</script>\\n\\n  <link rel=\"stylesheet\" media=\"all\" href=\"https://s.gr-assets.com/assets/goodreads-c5f711b78853214c2f6a61172b4a42d7.css\" />\\n\\n    <style type=\"text/css\" media=\"screen\">\\n    .bigTabs {\\n      margin-bottom: 10px;\\n    }\\n\\n    .list_read{\\n      background-color: #D7D2C4;\\n      float: left;\\n    }\\n  </style>\\n\\n\\n  <link rel=\"stylesheet\" media=\"screen\" href=\"https://s.gr-assets.com/assets/common_images-670d97636259cafc355c94fc43e871d7.css\" />\\n\\n  <script src=\"https://s.gr-assets.com/assets/desktop/libraries-41a429a5834e6352d597e2cf0b06486f.js\"></script>\\n  <script src=\"https://s.gr-assets.com/assets/application-7606609cafaf6fe4c5ef3af6b7d3302f.js\"></script>\\n\\n    <script>\\n  //<![CDATA[\\n    var gptAdSlots = gptAdSlots || [];\\n    var googletag = googletag || {};\\n    googletag.cmd = googletag.cmd || [];\\n    (function() {\\n      var gads = document.createElement(\"script\");\\n      gads.async = true;\\n      gads.type = \"text/javascript\";\\n      var useSSL = \"https:\" == document.location.protocol;\\n      gads.src = (useSSL ? \"https:\" : \"http:\") +\\n      \"//securepubads.g.doubleclick.net/tag/js/gpt.js\";\\n      var node = document.get'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "BCUhjOG5Ps8r",
        "outputId": "8047dbe7-133a-4b6b-9645-45c9c8b257ed"
      },
      "source": [
        "#Let us write a loop to fetch 2 pages of \"best-books\" from goodreads. \n",
        "#Notice the use of a format string. This is an example of old-style python format strings\n",
        "URLSTART=\"https://www.goodreads.com\"\n",
        "BESTBOOKS=\"/list/show/1.Best_Books_Ever?page=\"\n",
        "for i in range(1,3):\n",
        "    bookpage=str(i)\n",
        "    stuff=requests.get(URLSTART+BESTBOOKS+bookpage)\n",
        "    filetowrite=\"files/page\"+ '%02d' % i + \".html\"\n",
        "    print(\"FTW\", filetowrite)\n",
        "    fd=open(filetowrite,\"w\")\n",
        "    fd.write(stuff.text)\n",
        "    fd.close()\n",
        "    time.sleep(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FTW files/page01.html\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-61800a0c19d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfiletowrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"files/page\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'%02d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FTW\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiletowrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiletowrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'files/page01.html'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "aNaM_IulPs8s",
        "outputId": "787e82aa-7fda-42bd-f079-6f86e158af3c"
      },
      "source": [
        "#2. Parse the page, extract book urls\n",
        "\n",
        "#Notice how we do file input-output, and use beautiful soup in the code below. \n",
        "#The with construct ensures that the file being read is closed, something we do explicitly for the file being written. \n",
        "#We look for the elements with class bookTitle, extract the urls, and write them into a file\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "bookdict={}\n",
        "for i in range(1,3):\n",
        "    books=[]\n",
        "    stri = '%02d' % i\n",
        "    filetoread=\"files/page\"+ stri + '.html'\n",
        "    print(\"FTW\", filetoread)\n",
        "    with open(filetoread) as fdr:\n",
        "        data = fdr.read()\n",
        "    soup = BeautifulSoup(data, 'html.parser')\n",
        "    for e in soup.select('.bookTitle'):\n",
        "        books.append(e['href'])\n",
        "    print(books[:10])\n",
        "    bookdict[stri]=books\n",
        "    fd=open(\"files/list\"+stri+\".txt\",\"w\")\n",
        "    fd.write(\"\\n\".join(books))\n",
        "    fd.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FTW files/page01.html\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-aff6625c6350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfiletoread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"files/page\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstri\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FTW\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiletoread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiletoread\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'files/page01.html'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "j-dlVRbePs8s",
        "outputId": "923329ab-66a7-4149-fa4c-70c19d053619"
      },
      "source": [
        "#Here is George Orwell's 1984\n",
        "bookdict['02'][0]\n",
        "\n",
        "#Lets go look at the first URLs on both pages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d9647dac3e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Here is George Orwell's 1984\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbookdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'02'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Lets go look at the first URLs on both pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '02'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Ccqk3BLWPs8t",
        "outputId": "f189809b-9129-47c3-bc69-1f70a6954867"
      },
      "source": [
        "#3. Parse a book page, extract book properties\n",
        "#Ok so now lets dive in and get one of these these files and parse them.\n",
        "furl=URLSTART+bookdict['02'][0]\n",
        "furl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9984e3e5c5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3. Parse a book page, extract book properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Ok so now lets dive in and get one of these these files and parse them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfurl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mURLSTART\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbookdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'02'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '02'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "LQHSYqviPs8u",
        "outputId": "c27e2a62-fa8a-4ec5-adb3-4d8f95fcccbe"
      },
      "source": [
        "fstuff=requests.get(furl)\n",
        "print(fstuff.status_code)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1d5eadeebd6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfstuff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfurl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'furl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "nb8UMFHPPs8u",
        "outputId": "1f66165c-e440-435a-f8e1-38cdbb93ad1e"
      },
      "source": [
        "d=BeautifulSoup(fstuff.text, 'html.parser')\n",
        "d.select(\"meta[property='og:title']\")[0]['content']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dc18cfec9d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"meta[property='og:title']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fstuff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "tFrxbonIPs8u",
        "outputId": "58f2f0b1-878b-4074-c432-0fe822b82acd"
      },
      "source": [
        "#Lets get everything we want...\n",
        "d=BeautifulSoup(fstuff.text, 'html.parser')\n",
        "print(\n",
        "\"title\", d.select_one(\"meta[property='og:title']\")['content'],\"\\n\",\n",
        "\"isbn\", d.select(\"meta[property='books:isbn']\")[0]['content'],\"\\n\",\n",
        "\"type\", d.select(\"meta[property='og:type']\")[0]['content'],\"\\n\",\n",
        "\"author\", d.select(\"meta[property='books:author']\")[0]['content'],\"\\n\",\n",
        "\"average rating\", d.select_one(\"span.average\").text,\"\\n\",\n",
        "\"ratingCount\", d.select(\"meta[itemprop='ratingCount']\")[0][\"content\"],\"\\n\",\n",
        "\"reviewCount\", d.select_one(\"span.count\")[\"title\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-47102817da61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Lets get everything we want...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfstuff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m print(\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"meta[property='og:title']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\"isbn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"meta[property='books:isbn']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fstuff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PPB7VmRDPs8v",
        "outputId": "1c51611d-53a8-429f-fbca-704d44b8f123"
      },
      "source": [
        "#Ok, now that we know what to do, lets wrap our fetching into a proper script. \n",
        "#So that we dont overwhelm their servers, we will only fetch 5 from each page, but you get the idea...\n",
        "#We'll segue of a bit to explore new style format strings. See https://pyformat.info for more info.\n",
        "\n",
        "\"list{:0>2}.txt\".format(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'list03.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-IHHgbyPs8v"
      },
      "source": [
        "a = \"4\"\n",
        "b = 4\n",
        "class Four:\n",
        "    def __str__(self):\n",
        "        return \"Fourteen\"\n",
        "c=Four()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEYlQTZUO20i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6E2yUCgPs8v"
      },
      "source": [
        "\"The lazy cat jumped over the {} and {} and {}\".format(a, b, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX6dLKYnPs8w"
      },
      "source": [
        "#4. Set up a pipeline for fetching and parsing\n",
        "\n",
        "fetched=[]\n",
        "for i in range(1,3):\n",
        "    with open(\"files/list{:0>2}.txt\".format(i)) as fd:\n",
        "        counter=0\n",
        "        for bookurl_line in fd:\n",
        "            if counter > 4:\n",
        "                break\n",
        "            bookurl=bookurl_line.strip()\n",
        "            stuff=requests.get(URLSTART+bookurl)\n",
        "            filetowrite=bookurl.split('/')[-1]\n",
        "            filetowrite=\"files/\"+str(i)+\"_\"+filetowrite+\".html\"\n",
        "            print(\"FTW\", filetowrite)\n",
        "            fd=open(filetowrite,\"w\", encoding='utf-8')\n",
        "            fd.write(stuff.text)\n",
        "            fd.close()\n",
        "            fetched.append(filetowrite)\n",
        "            time.sleep(2)\n",
        "            counter=counter+1\n",
        "            \n",
        "print(fetched)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zvNJvxRPs8w"
      },
      "source": [
        "# Ok we are off to parse each one of the html pages we fetched. \n",
        "# We have provided the skeleton of the code and the code to parse the year, \n",
        "#since it is a bit more complex...see the difference in the screenshots above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu-8tp9yPs8w"
      },
      "source": [
        "import re\n",
        "yearre = r'\\d{4}'\n",
        "def get_year(d):\n",
        "    if d.select_one(\"nobr.greyText\"):\n",
        "        return d.select_one(\"nobr.greyText\").text.strip().split()[-1][:-1]\n",
        "    else:\n",
        "        thetext=d.select(\"div#details div.row\")[1].text.strip()\n",
        "        rowmatch=re.findall(yearre, thetext)\n",
        "        if len(rowmatch) > 0:\n",
        "            rowtext=rowmatch[0].strip()\n",
        "        else:\n",
        "            rowtext=\"NA\"\n",
        "        return rowtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiJbuX0WPs8x"
      },
      "source": [
        "#Your job is to fill in the code to get the genres.\n",
        "def get_genres(d):\n",
        "    # your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCGZOTPvPs8x"
      },
      "source": [
        "listofdicts=[]\n",
        "for filetoread in fetched:\n",
        "    print(filetoread)\n",
        "    td={}\n",
        "    with open(filetoread) as fd:\n",
        "        datext = fd.read()\n",
        "    d=BeautifulSoup(datext, 'html.parser')\n",
        "    td['title']=d.select_one(\"meta[property='og:title']\")['content']\n",
        "    td['isbn']=d.select_one(\"meta[property='books:isbn']\")['content']\n",
        "    td['booktype']=d.select_one(\"meta[property='og:type']\")['content']\n",
        "    td['author']=d.select_one(\"meta[property='books:author']\")['content']\n",
        "    td['rating']=d.select_one(\"span.average\").text\n",
        "    td['ratingCount']=d.select_one(\"meta[itemprop='ratingCount']\")[\"content\"]\n",
        "    td['reviewCount']=d.select_one(\"span.count\")[\"title\"]\n",
        "    td['year'] = get_year(d)\n",
        "    td['file']=filetoread\n",
        "    glist = get_genres(d)\n",
        "    td['genres']=\"|\".join(glist)\n",
        "    listofdicts.append(td)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUhU6UZZPs8y"
      },
      "source": [
        "listofdicts[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGEkCvGcPs8y"
      },
      "source": [
        "#Finally lets write all this stuff into a csv file which we will use to do analysis.\n",
        "df = pd.DataFrame.from_records(listofdicts)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGHnR9DPs8y"
      },
      "source": [
        "df.to_csv(\"files/meta.csv\", index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}